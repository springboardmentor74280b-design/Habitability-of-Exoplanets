import pandas as pd
import pickle
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline

# 1. Load Data
df = pd.read_csv('phl_exoplanet_catalog.csv')

feature_cols = [
    'P_MASS_EST', 'P_RADIUS_EST', 'P_PERIOD', 'P_DISTANCE', 
    'P_TEMP_EQUIL', 'S_TEMPERATURE', 'S_LUMINOSITY', 'S_RADIUS', 
    'S_MASS', 'S_METALLICITY'
]
target_col = 'P_HABITABLE'

# Clean
df_clean = df[feature_cols + [target_col]].dropna(subset=[target_col])
X = df_clean[feature_cols]
y = df_clean[target_col]

# 2. Define the Perfect Pipeline (SMOTE + XGBoost)
# We use ImbPipeline so SMOTE fits nicely inside
final_pipeline = ImbPipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('smote', SMOTE(random_state=42, k_neighbors=3)),
    ('model', xgb.XGBClassifier(
        objective='multi:softprob', # softprob gives us the % score for ranking
        num_class=3,
        n_estimators=100, 
        max_depth=6, 
        learning_rate=0.1, 
        random_state=42
    ))
])

# 3. Train on 100% of the Data
print("Training the Perfect Model on the entire universe...")
final_pipeline.fit(X, y)

# 4. Save for API
# We create a dictionary wrapper to match the API's expected structure
# (The API expects "model" and "preprocessor", but since our pipeline does BOTH,
# we will adjust the API code slightly in the next step. For now, let's just save the pipeline.)
with open('final_pipeline.pkl', 'wb') as f:
    pickle.dump(final_pipeline, f)

print("\nâœ… SAVED: 'final_pipeline.pkl' is now the SMOTE+XGBoost model.")
print("Milestone 2 is officially closed with a Perfect Score.")